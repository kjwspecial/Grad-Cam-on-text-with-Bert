{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/kjwspecial/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "### bert tokenizer\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')    # Download vocabulary from S3 and cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모든 sentence에 CLS, SEP 붙인다.\n",
    "def get_token(text):\n",
    "    text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    return tokenized_text\n",
    "\n",
    "# 2. token index로 변환, padding 한다.\n",
    "def get_ids(tokenized_text, max_length):\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    input_ids = indexed_tokens + [0]*(max_length - len(indexed_tokens))\n",
    "    return input_ids\n",
    "\n",
    "# 3. segment_ids를 만든다.\n",
    "def get_mask(input_ids):\n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    return attention_masks\n",
    "\n",
    "def df_one_hot_encoded(df,column_name):\n",
    "    df_one_hot_encoded = pd.get_dummies(df[column_name])\n",
    "    target = np.array(df_one_hot_encoded)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_setting(df,name):\n",
    "    '''\n",
    "        max_len : description 최대길이\n",
    "        description : token 변환\n",
    "        \n",
    "        df.OFFENSE_TYPE_ID[i] = get_token(ID)\n",
    "        리스트를 copy해서 하기때문에 느린듯, 권장X\n",
    "    '''\n",
    "    #[CLS] [SEP] 붙임, token 변환\n",
    "    description = df[\"description\"]\n",
    "    description = [get_token(x) for x in description]\n",
    "    \n",
    "    #max_len\n",
    "    max_len=0\n",
    "    for ID in description:\n",
    "        if(max_len < len(ID)):\n",
    "            max_len=len(ID)       \n",
    "    \n",
    "    #convert Id + padding\n",
    "    input_ids = [get_ids(x,max_len) for x in description]\n",
    "    \n",
    "    #Attention_masks\n",
    "    attention_masks = []\n",
    "    attention_masks = get_mask(input_ids)\n",
    "    \n",
    "    #labels\n",
    "    one_hot_target = df_one_hot_encoded(df,name)\n",
    "    target = np.argmax(one_hot_target,axis=1)\n",
    "    \n",
    "    # class수\n",
    "    num_classes=len(df[name].unique())\n",
    "    \n",
    "    return input_ids, target,  attention_masks, num_classes , description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## concat한것\n",
    "def concat_text(sentence):\n",
    "    vocab = list(tokenizer.vocab.keys())\n",
    "    concat_text=''\n",
    "    for word in sentence:\n",
    "        if word ==0:\n",
    "            break\n",
    "        if vocab[word][0]!='#':\n",
    "            concat_text += ' '+vocab[word]\n",
    "        else:\n",
    "            concat_text +=''+vocab[word][2:]\n",
    "    return concat_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
